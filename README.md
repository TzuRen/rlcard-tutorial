# RLCard Tutorial
This is an official tutorial for [RLCard: A Toolkit for Reinforcement Learning in Card Games](https://github.com/datamllab/rlcard). We provide step-by-step instructions and running examples with Jupyter Notebook for both **Python** and **R**. The Python tutorial is available in Colab, where you can try your experiments in the cloud interactively.
*   Official Website: [http://www.rlcard.org](http://www.rlcard.org)
*   Paper: [https://arxiv.org/abs/1910.04376](https://arxiv.org/abs/1910.04376)
*   Resources: [Awesome-Game-AI](https://github.com/datamllab/awesome-game-ai)

## For Python
### Tutorials in Jupyter Notebook
*   [Having Fun with Pretrained Leduc Model](https://github.com/datamllab/rlcard-tutorial/blob/master/python/leduc_holdem_pretrained.ipynb)
*   [Training DQN on Blackjack](https://github.com/datamllab/rlcard-tutorial/blob/master/python/blackjack_dqn.ipynb)
*   [Running multiple processes](https://github.com/datamllab/rlcard-tutorial/blob/master/python/blackjack_mutiple_process.ipynb)
*   [Leduc Hold'em as single-agent environment](https://github.com/datamllab/rlcard-tutorial/blob/master/python/leduc_single_agent.ipynb)
*   [Training CFR on Leduc Hold'em](https://github.com/datamllab/rlcard-tutorial/blob/master/python/leduc_holdem_cfr.ipynb)

### Links to Colab
*   [Having Fun with Pretrained Leduc Model](https://colab.research.google.com/github/mia1996/rlcard-tutoirial/blob/master/leduc_holdem_pretrained.ipynb)
*   [Training DQN on Blackjack](https://colab.research.google.com/github/mia1996/rlcard-tutoirial/blob/master/blackjack_dqn.ipynb)
*   [Running multiple processes](https://colab.research.google.com/github/mia1996/rlcard-tutoirial/blob/master/blackjack_mutiple_process.ipynb)
*   [Leduc Hold'em as single-agent environment](https://colab.research.google.com/github/mia1996/rlcard-tutoirial/blob/master/leduc_single_agent.ipynb)
*   [Training CFR on Leduc Hold'em](https://colab.research.google.com/github/mia1996/rlcard-tutoirial/blob/master/leduc_holdem_cfr.ipynb)

## For R
This tutorial uses [reticulate](https://rstudio.github.io/reticulate/) to call RLCard with R interfaces. Please make sure that you have **Python 3.5+** and **pip** installed.

*   [Training DQN on Blackjack](https://github.com/datamllab/rlcard-tutorial/blob/master/r/blackjack_dqn/blackjack_dqn.ipynb)
*   [Training CFR on Leduc Hold'em](https://github.com/datamllab/rlcard-tutorial/blob/master/r/leduc_holdem_cfr/leduc_holdem_cfr.ipynb)
*   [Leduc Hold'em as single-agent environment](https://github.com/datamllab/rlcard-tutorial/blob/master/r/leduc_single_agent/leduc_single_agent.ipynb)
*   [Texas Hold'em nolimit](https://github.com/datamllab/rlcard-tutorial/blob/master/r/nolimit_holdem/nolimit_holdem.ipynb)
*   [Running Random agent on Blackjack](https://github.com/datamllab/rlcard-tutorial/blob/master/r/blackjack_random/blackjack_random.ipynb)

## Contributing
Contribution to this project is greatly appreciated! Please create an issue/pull request for feedbacks or more tutorials.

## Cite this work
If you find this repo useful, you may cite:
```bibtex
@article{zha2019rlcard,
  title={RLCard: A Toolkit for Reinforcement Learning in Card Games},
  author={Zha, Daochen and Lai, Kwei-Herng and Cao, Yuanpu and Huang, Songyi and Wei, Ruzhe and Guo, Junyu and Hu, Xia},
  journal={arXiv preprint arXiv:1910.04376},
  year={2019}
}
```

## Acknowledgements
The R tutorial is mainly based on the code provided by [@systats](https://github.com/systats). See [here](https://github.com/datamllab/rlcard/issues/96).
