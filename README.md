# rlcard-tutorial
In this tutorial for rlcard, we provide some toy exmples in the versions of Python and R. To simplify the implementation process and make it easier for beginners, we made it in Jupyter Notebook and Colab. Now you can train your first rlcard model with barely installation and setup. Have fun with your first trained rlcard!


For R version, we provide these toy examples in Jupyter Notebook:
*   [Training DQN on Blackjack](https://github.com/datamllab/rlcard-tutorial/blob/master/R-rlcard-tutorial/Deep-Q_learning_blackjack/Deep-Q_Learning_Blackjack.ipynb)
*   [Training CFR on Leduc Hold'em](https://github.com/datamllab/rlcard-tutorial/blob/master/R-rlcard-tutorial/CFR_leduc_holdem/CFR_leduc_hold'em.ipynb)
*   [Leduc Hold'em as single-agent environment](https://github.com/datamllab/rlcard-tutorial/blob/master/R-rlcard-tutorial/Random_agent_blackjack/Random_agent_blackjack.ipynb)
*   [Texas Hold'em nolimit](https://github.com/datamllab/rlcard-tutorial/blob/master/R-rlcard-tutorial/Texas_holdem_nolimit/r-rlcard_no-limit_Texas_Holdem.ipynb)
*   [Running Random agent on Blackjack](https://github.com/datamllab/rlcard-tutorial/blob/master/R-rlcard-tutorial/Random_agent_blackjack/Random_agent_blackjack.ipynb)

For Python version, we provide these toy examples in Colaboratory:
*   [Having Fun with Pretrained Leduc Model](https://github.com/datamllab/rlcard-tutorial/blob/master/Python-rlcard-tutorial/leduc_holdem_pretrained.ipynb)
*   [Training DQN on Blackjack](https://colab.research.google.com/github/mia1996/r-rlcard_test/blob/master/Blackjack_dqn.ipynb)
*   [Running multiple processes](https://colab.research.google.com/github/mia1996/r-rlcard_test/blob/master/Blackjack_mutiple_process.ipynb)
*   [Leduc Hold'em as single-agent environment](https://colab.research.google.com/github/mia1996/r-rlcard_test/blob/master/Leduc_single_agent.ipynb)
*   [Training CFR on Leduc Hold'em](https://colab.research.google.com/github/mia1996/r-rlcard_test/blob/master/leduc_holdem_cfr.ipynb)
